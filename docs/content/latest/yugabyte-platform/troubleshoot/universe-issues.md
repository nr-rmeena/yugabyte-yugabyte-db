---
title: Troubleshoot Universe Issues
headerTitle: Troubleshoot Universe Issues
linkTitle: Universe issues
description: Troubleshoot universe issues
aliases:
  - /troubleshoot/enterprise-edition/universes/
  - /latest/troubleshoot/enterprise-edition/universes/
menu:
  latest:
    identifier: universe-issues
    parent: troubleshoot-yp
    weight: 20
isTocNested: true
showAsideToc: true
---

Yugabyte Platform provides means to monitor and troubleshoot issues that arise from universes.

## Use Metrics

A universe's **Metrics** page displays graphs representing information on operations, latency, and other parameters accumulated over time for each type of node and server. Examining specific metrics allows you to diagnose and troubleshoot issues.

You access metrics by navigating to **Universes > Universe-Name > Metrics**, as shown in the following illustration:

![Metrics Page](/images/yp/metrics.png)

You should do the following on a regular basis:

- Monitor remote bootstrap for node failures. You can access this metric via **Tablet Server > Remote Bootstraps** and **Tablet Server > RPC Queue Size**.
- Monitor the NTP server to ensure that it is running. You can access this information via your computer's operating system.
- Monitor clock skew so you can see when the clock is off by more than 500 milliseconds. You can access this metric via **Node > Clock Skew**.
- Monitor your disk usage. The default is 80% used, but you should consider this metric in the context of  your environment. For example, the usage percentage can be higher on larger disks; some file systems issue an alert at 75% usage due to performance degradation. You can access this metric via your computer system.
- Monitor YSQL and YCQL operations latency and tune it according to your application service level agreement. You can access this metrics via **YSQL Ops and Latency**, **YCQL Ops and Latency**, **YSQL Advanced**, and **YSQL Advanced**. 
- Monitor average read and write latency so you know when latency starts to degrade, at which point you should tune it according to averages. You can access this metric via **Tablet Server > Average Latency**.
- Monitor reactor delays to measure bottleneck of incoming requests. You can access this metric via **Tablet Server > Reactor Delays**.
- Monitor log statistics per node to measure churn in the log cache size to determine high rate of evictions. You can access this metric via **Tablet Server > WAL Stats / Node**.
- Monitor the tablet and master servers' RPC queue size so you can see all the subelements and know if there is a bottleneck that might cause performance degradation. You can access this metric via **Tablet Server > RPC Queue Size** and **Master Server > RPC Queue Size**.
- Monitor DocDB cache miss ratio so you can tune the cache when necessary. You can access this metric via **DocDB > Cache Hit & Miss**.

The following tables describe all the metrics available via the Yugabyte Platform UI.

### YSQL Ops and Latency

| **Graph**             | **Description**                                              | **Alert Guidance**                                           | **Example**                                                  |
| :-------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Total YSQL Ops / Sec  | Count of DELETE, INSERT, SELECT, and UPDATE statements through the YSQL API. <br>This does not include index writes. | An alert should be issued if count drops significantly lower than your average count, as this might indicate an application connection failure. In addition, an alert should be issued if the count is much higher than your average count, as this could indicate a DDoS, security incident, and so on.<br>It is recommended to coordinate this with the application team because there could be legitimate reasons for dips and spikes. | ![img](https://lh4.googleusercontent.com/2wQzDQE8YBHfvkCpL9MJCnaNOQUIesfYrb3siZZJY1m3i1Si7MiaX9nblSl6rVhLYqFS6XMkY5YpuflFVCxwIvuOpcoNvASt6kWFciEyXqVVbLnZeyViZb3kxYdxE5RdAaOwIj1F=s1600) |
| YSQL Op Latency (Avg) | Average time in milliseconds of DELETE, INSERT, SELECT, and UPDATE statements through the SQL API. | An alert should be issued when the overall latency is close to or higher than your application SLA.<br>Note that the overall latency metric is less helpful for troubleshooting specific queries. It is recommended that the application track query latency.<br>Note that there could be reasons your traffic experiences spikes in latency. For example, ad-hoc queries such as count(*) are executed. | ![img](https://lh3.googleusercontent.com/QVaVhN7VrBLoScY3ggRa2kljErmCjB60bURKulpaUwpT_af_mtnyHS4eZmmwwjhJd0F9c-NFAGVKe8qpdvIGX20OCVdBTfi5ZIm4xEk7bjZN6zhoPQ48-N9UDcmRLNDZhn8eKMLB=s1600) |

### YCQL Ops and Latency

| **Graph**             | **Description**                                              | **Alert Guidance**                                           | **Example**                                                  |
| :-------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Total YCQL Ops / Sec  | Count of DELETE, INSERT, SELECT, and UPDATE transactions, as well as other statements through the YCQL API. | An alert should be issued if count drops significantly lower than your average count, as this could indicate an application connection failure. | ![img](https://lh3.googleusercontent.com/TW5JSRh7CO5PvynR12IlY_CQ1AnQUYHpA66AGR23rId6eEmLYGfUlVBmweMve96Jfj0y0WC5bCqePcdpklNwxofGUhizq70P2cXf2i8WKbiB5iNd_87iZ4b3zav9RtwkPvNCNaHe=s1600) |
| YCQL Op Latency (Avg) | Average time in milliseconds of DELETE, INSERT, SELECT, and UPDATE transactions, as well as other statements through the YCQL API. | An alert should be issued when latency is close to or higher than your application SLA. | ![img](https://lh4.googleusercontent.com/WxcZwZQsXhmRmg7b9gz_HHKL6xm4G03ev5GN43aU38-EsMjn4fmIVWaQMnFFVRiMrHKg62klA0OudQnn6AI35wmYmA32xBL7zNr0fmmVdx5XL5CMdOZLYi8afS8dbMPzs_ojackj=s1600) |
| YCQL Op Latency (P99) | Average time in milliseconds of top 99% of DELETE, INSERT, SELECT, and UPDATE transactions, as well as other statements through the CQL API. |                                                              | ![img](https://lh6.googleusercontent.com/sHpE4ep0Jk3__OQlCBO5XMHMQKy-atlXnNXKVNwGsm3FPKAZjlJzNZzlhPel73bZsSVNixZ66V5-ELzkJI0s_KeW-HBv9cyUl7TM1IrheVO5CyROtyvYNhSswqCeq8t6D0WZejKJ=s1600) |

### Node

Node metrics should be considered on a per-node basis.

| Graph                                 | **Description**                                              | **Alert Guidance**                                           | **Example**                                                  |
| :------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| CPU Usage                             | Percentage of CPU utilization on nodes being consumed by the tablet or master server Yugabyte processes, as well as other processes, if any.<br>In general, CPU usage is a measure of all processes running on the server.<br>User CPU time is the amount of time the processor worked on all the processes.<br>System CPU time is the amount of time the processor worked on the operating systemâ€™s functions connected to the processes. |                                                              | ![img](https://lh3.googleusercontent.com/VNR1aPLmSboyuk7UU4pdfJ7y5zl0WVytVZ9kjXziciw-D2EEkodp15JLTX2DIuib11otPhZr4tMdwFuVb61ebcQtv3JGZ1azVMoh_ypRohu_fr7qjOAaTapN2AETgt8H6eyoRqwV=s1600) |
| Memory Usage (Buffered, Cached, Free) | Amount of RAM in GB available to nodes in the cluster.<br>Buffered memory is the size of in-memory block input/output buffers. Cached memory is the size of the page cache. Free memory is not in use. | An alert should not be issued on memory metrics directly. It is recommended to use another metric to troubleshoot the underlying problem causing any memory bottlenecks. The assumption is that the computer is dedicated to Yugabyte processes, therefor Yugabyte processes aggressively use the memory provided for caches and other operations. | ![img](https://lh4.googleusercontent.com/2ZMbLXZrkTbRLugLvVB0DKd1Sx4U06luJj1FQa03j_AsbvC4zCuUwY7eUmCg4xF6ZOb-WtyK47zB8sp_5qSqYSIETAvN2wsI9uZDX5suBq1KK_XGtJhzYF2Ya0YpW3QumyD6DIFE=s1600) |
| Disk IOPS / Node                      | Number of disk input/output read and write operations per second averaged over each node. | Large spikes usually indicate large compactions. Rarely, in cases of a spiky workload, this could indicate block cache misses. Since random reads always hit disk, it is recommended to increase IOPS capacity for this type of workload.<br>You should set an alert to a value much greater than your average or as a percentage of your available IOPS. This value is averaged across all nodes in a cluster. An alert should be issued per node to detect source of underlying issues. | ![img](https://lh4.googleusercontent.com/Ib_M6hdrTY4HEkHbP8N2wgha4EgtvB8YvjBxDe9XrDlUAipYVx8vfT3jCWuMKJpAnBPhkzEOHSKPm1i0L-kXPte6jc-GgjWilI6x_mZXcUmJjfP5NQnvfGPHqujpFg-F2TLbyVNI=s1600) |
| Disk Bytes / Sec / Node               | Number of bytes (scale is in millions) being read or written to disk per second, averaged over each node. | If the max iops for the instance volume type has high utilization, first be sure the schema and query are optimized. As a secondary step, increase the instance volume iops capacity. | ![img](https://lh4.googleusercontent.com/hndA-admKvbVxkpb1xBuJn5FNeLmhsG-b_fCJDfUDwZxsGQ0YCjPH_Al3-wnood9ExsmlnIhu8N9B2V1Bmv28gTiYWQ5TfDLd8ZrmJFr1_i32xG_PIGbL0S7AxTbdeLHa4AnN1cq=s1600) |
| Network Packets / Sec / Node          | Count of network packets received to the server (RX) and transmitted from the server (TX) per second, averaged over nodes. |                                                              | ![img](https://lh4.googleusercontent.com/0VbMxd8scSqhrDFV1pS6AgjVbb6fDAVEyyGxlfnqB7HrprBCZhicP5YfZYw0J9H-xf5zrvuglCO5GPa6kmAcLiACjArBQ6-tDt6LVKu5Jh3Iu5huMgMPRFNsZXzwVEKBIsJSn7r1=s1600) |
| Network Bytes / Sec / Node            | Size (in bytes; scale is in millions) of network packets received (RX) and transmitted (TX) per second, averaged over nodes. |                                                              | ![img](https://lh3.googleusercontent.com/c4llgQ0yzArWSGZVbQMYoJLEd211s8p03CmBxHsSCpvAf5shNakXBcsrfeVZeigMqW-hiyiCTem7J_75i9AAsgbdUdnnNt8kmDYcbdyEPmNVPAmrg3RhbMYnts2tOytJD2E1N-wf=s1600) |
| Network Errors / Sec / Node           | Count of errors related to network packets received (RX) and transmitted (TX) per second, averaged over nodes. | Unless the environment throws a lot of errors, alert on any errors. | ![img](https://lh4.googleusercontent.com/ixqjLVncwiA29zOvus4D8fRP5F9dhwDrXkEnkaLldc-pwvln5_mOicTlb2SI_2_qcZwwgtFZVTrhO4j0zAx2BP38PcboRTVZDeN_xOwh4EGm8JleDWJ6jd8_IyYttoZ3i-dLU9VP=s1600) |
| System Load Over Time                 | Measure of system load averaged over 1, 5, and 15 minutes.  In the UI, these are marked as small, medium, and large. | Values greater than your configured number of cores indicates that processes are waiting for CPU time.  Consider your averages when determining the alert threshold. In some cases, this can mean alerting when the 5-minute load average is at 75-80% of available cores on the server. For some systems and workloads, you may want to set the threshold higher, for example, to 4x the number of cores. | ![img](https://lh3.googleusercontent.com/ZwPDfTJI8T1CsD-uCwl-q9pQECmhAxTkaEXFTLlZr-HgjZMcaVnU5r2x37srKua7MXlSeCeBlq4U0wDewfBKSgqT8ssi-gN8YZcwjzlYTqdp0AJvYxhVhwcMI4STMRVZy4ZJthsl=s1600) |
| Clock Skew                            | For YugabyteDB to preserve data consistency, the clock drift and clock skew across different nodes are configured within bounds. | Clock skew is important for performance and data consistency. The OSS product will refuse to come up / crash at a default value of 500 ms [citation needed], as it is considered better to be down than inconsistent. The platform alerts at the same threshold, and it should be considered a top priority to resolve this alert. | ![img](https://lh4.googleusercontent.com/18r0K-JTy679l3GJS8MoSzzID0CYuw88RdVrq6eEMovOhB5o3mmvY5s2t4TVe7oFFYhiU1vl_twxh_bG99XB8xu5d1NJ3DRjxiKvQm0vmGj-YUYNra8CM7mt_Zyn8d0QMZPux6IH=s1600) |

### YCQL Advanced

| **Graph**                     | **Description**                                              | **Alert Guidance**                                           | **Example**                                                  |
| ----------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| YCQL Latency Breakdown        | Average time (in milliseconds) spent by the CQL API parsing and executing operations. |                                                              | ![img](https://lh5.googleusercontent.com/tQ5cDNEhs4506zjQOVEHo0UpVgJUZSm4Igt6ZJ5YY6HnTog5ImPX2uLTL8hzdQGP7Fj7FSHFO_UDQI2Z40YaJxXVTTUaGaIlHyOsUaVgiTBwIDUj1Aa9bKmXG8ul0SrZroBGfU1s=s1600) |
| YBClient Ops Local vs Remote  | Count of local and remote read and write requests.  Local requests are executed on the same node that received the request.  Remote requests are re-routed internally to a different node for executing the operation. | If an application is using a Yugabyte driver that supports local query routing optimization and prepared statements, the expected value for this is close to 100% local for local reads and writes. If using the Cassandra driver or not using prepared statements, expect to see a relatively even split (e.g., ~33% local and ~66% remote for a 3-node cluster). | ![img](https://lh3.googleusercontent.com/vCjCLk5zKT4ydXaK680lVtXji6DK87y-os8p_qYsYZrjigsyk6qtq-Wkj4RFflynkfiQLETQrqY5Nx5uJxto7Qh4W3f9MGiQQ0-jOvzlqwEpmkqXrSE0Ef5BweVSk4OHeJ21wKO9=s1600) |
| YBClient Latency              | Latency of local and remote read and write requests.  See above regarding local and remote requests. |                                                              | ![img](https://lh5.googleusercontent.com/_3Kc41Wpi-xd0Mo78uv0DLPHjAAIYeQapcHs2Ksq-n9-ej81nGc4xwuoLKm2lY_u7pqONe1ZTFSVwM8LQlWpWlNPNLkoIwdDmCMPfS66LG-Y10jT41cogRn8BZuLw5fMUr0hfs5S=s1600) |
| Reactor Delays                |                                                              | This value should be close to zero. If it is growing or stays higher, it is an indicator that the system is being overloaded or that queues are backing up. In this case, investigate throughput and queue size/latency metrics for tuning guidance. | **![img](https://lh3.googleusercontent.com/Jf64-zZxYjy7DR4rlLB-Nd8vNR6Jlknie74y8he9-wPEP4mjVQCTCr4UeghnC6Vy1H-ihZHysQdxQi2AtLe2Mt6IAyAHMiR9z-raon4QUFW2GPrZRCgrp9NWQBTRM2BI302ebIcC=s1600)** |
| RPC Queue Size                | Number of RPCs in service queue.                             | Queue size is an indicator of incoming traffic and throughput. In general, this will show very low values (Yugabyte is processing requests at a health rate) or a flat line at the max configured queue size (Yugabyte has filled the queues and can't process fast enough). | ![img](https://lh5.googleusercontent.com/01_C5AMjCHipgNzqpnIm1CL2QbVNc58bWQ7J-QBHj84N8jr2tXvU91GMAdyydscJ7-QP232Q4lw3ZYzoW1W-dDBNVAApXg5M4s15Vj6G2opgPAaajS6Tb94k9v8hQ6o6YjRULVOj=s1600) |
| Response Size (bytes)         |                                                              |                                                              | ![img](https://lh3.googleusercontent.com/Z_dpGe3-GwYKHu95SZ2WXpZrYAKaGuhTN71fBAX9Dj0vcWUYXlVFZZC25KS2AJ-Q7uPMtXuVq1VsoZ9ZOeMu9fBSdXHMAd8Ex0JxUCpb2I5EXc9NO9TlkiKPXaEx5vjUSX1Y4RJ6=s1600) |
| Transaction                   |                                                              |                                                              | ![img](https://lh3.googleusercontent.com/9n93fuRwV3uJCbr-uqt0q2doJXAY-tkl4kvTRyxW3-uGrQybuDkLBcgW58h00GRCjrEnC0EBa9UDeaY2VsaQC6G_cMtMr4IVg6DDO9uJE9XeAvpyk-JzjpNoHCCxHRSEIQ4a1zpk=s1600) |
| Inbound RPC Connections Alive | Count of current connections at the CQL API level.           | If this spikes to a number much higher than your average, consider that there may be an active DDoS or security incident. | ![img](https://lh5.googleusercontent.com/0dP5t_9SLO4TFS9coGLDtdJ3lfou7Xv3aVUzUkGKC-hoezLG96OnDeFPQlPGcKO0yiYh5B7aaXdydeR5JctdkMxe9_HUKn2-yR0tWsONFMUve31_8hgoufnWRMELsWMBrYZo2UA7=s1600) |

### Tablet Server

| **Graph**                            | **Description**                                              | **Alert Guidance**                                           | **Example**                                                  |
| ------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Ops / Sec / Node                     | This is the key throughput measure.  Read: Count of read operations at the tablet level. Write: Count of write operations at the tablet level. |                                                              | ![img](https://lh3.googleusercontent.com/cjPw8zr6FSmRHJrfaRnWnveP3pQFHsP5-pOYLKwOVG4MVeqzp4vfrz5nqSeYposbVqsCIszLRTQTTGLIskU94Ld3TTJwKnsX_SM8SyMhXQZEvnwrrRui1uqFhsTNeg3U5lLt-U-w=s1600) |
| Average Latency                      | Read: Average latency of read operations at the tablet level. Write: Average latency of write operations at the tablet level. |                                                              | ![img](https://lh5.googleusercontent.com/5jbF6GaIjI8vwmtozy1QYUlSXUVG6wACjmoy-goKVr0dXBRlC3R-fSrNj5FtbbcItx-ch5BAVuWwwy9C8Dekt-S-O23Hm6c-ie1c9j3aw9xz0HqQZof_OpM-1IxIyD1wMBggVTNf=s1600) |
| Reactor Delays                       | Number of microseconds incoming RPC requests spend in the worker queue. *Reactor* is a software implementation of a ring queue. | If this metric remains at a high level, it indicates the queues are full. | ![img](https://lh5.googleusercontent.com/D5xvYbkXwKs5-82pOAYfZaPiEi0Pb2CmY2hPTM4rQlh93pqLyt0me8iKV9-XqmZdK65O8V8PCk5QnBvqdSFJEgz-QkwqLPNQoYtta1Rfq5rpQpwPdrjt6KTMbLjBBevNdn9t4iF0=s1600) |
| Threads                              | Running: Current number of running threads. Started: Total number of threads started on this server. |                                                              | ![img](https://lh3.googleusercontent.com/eqIjp8APtkzyOJ5T-erkxlnCOT55tpI0lynPGHHbQK--QeLHOjQgHJwY_31hkYSr6kfUis09oCObDefODl_c9YNxjSSrbfo6vGHL_lgqpxR_WTsH7NMxiMLLb-z-d9ZHFVi66Qt9=s1600) |
| Consensus Ops / Sec                  | YugaByte implements the RAFT consensus protocol, with minor modifications. Update: Replicas implement an RPC method called UpdateConsensus which allows a leader to replicate a batch of log entries to the follower. Only a leader may call this RPC method, and a follower will only accept an UpdateConsensus call with a term equal to or higher than its currentTerm. Request: Replicas also implement an RPC method called RequestConsensusVote, which is invoked by candidates to gather votes. | A high number for thie Request Consensus indicates a lot of replicas are looking for a new election because they haven't received a heartbeat from the leader. High CPU or a network partition can cause this, and therefore this is a good candidate for alerting. | ![img](https://lh5.googleusercontent.com/Nh8HdshkIp6HOv8zHMYE0_D-YJnVQhWsoIQHKY5X3i9RQoPw9vAUYHZfb7ensZhxILyshsXl5rG8RWKZqZJlNN3OFl3C61O94LcCWipV8aDPUgZSHvAAkXEEPiph-eo2aalONPPl=s1600) |
| Total Consensus Change Config        | Related to the Raft Consensus Process. ChangeConfig: Number of times a peer was added or removed from the consensus group.  LeaderStepDown: Number of leader stepdowns (change in leader). LeaderElectionLost: Number of times a leader election has failed. RunLeaderElection: Count of leader elections due to a node failure or network partition. | Alert on LeaderElectionLost. An increase in ChangeConfig generally happens when Yugabyte needs to move data around. This could happen as the result of a planned server addition or decommission, or a server crash looping. A LeaderStepDown can indicate a normal change in leader, or could be an indicator of high CPU, blocked RPC queues, server retstarts, etc. Consider alerting on LeaderStepDown as a proxy for other system issues. | ![img](https://lh5.googleusercontent.com/qpcfgy-mrnNG32bkNkLt2VkudeRuiujuJD5uvXsZWP4zEUAnlVzVAoashC0U1xjg7m8Hgv6wtK90H5ATmwF4SP63CBZbsrTBLOSaOm98GcQce3lWJFlm2YRjEMpTcBWN_RFpBzla=s1600) |
| Remote Bootstraps                    | Total count of remote bootstraps.                            | When a RAFT peer fails, YugabyteDB executes an automatic remote bootstrap to create a new peer from the remaining ones.  Bootstrapping can also be the results of planned user activity, when adding or decommissioning nodes.  Consider alerting on a change in this count outside of planned activity. | ![img](https://lh4.googleusercontent.com/nC6S3IGke-0Zz9fPsrGETPUsIhXkNjmfLxdEisHd9lud1XKq3to9f7wnYBLIvt-jTKBxqaBbLrzqRk81boix5FqCCTj2mhtL5rgeaZanXgCfp8E3PtJPT-mfB2AjC4pbZIp2hyxY=s1600) |
| Consensus Rpc Latencies              | RequestConsensus: Latency (in milliseconds) of consensus request operations as described above. UpdateConsensus: Latency (in milliseconds) of consensus update operations as described above. |                                                              | ![img](https://lh5.googleusercontent.com/caywUG9k3Q316LDtViXi64lyKjTigNasUC_CTG-M-35Y5D-3P-bWZRov_lXCpvX5s8ThzygEvNmDpQsA9CUzCZEvzuEbeQEJtkw7OLfdrVTn2blwEOpTb0t11iuzIOVNs_dUb1fM=s1600) |
| Change Config Latency                | Latency (in microseconds or milliseconds) of consensus change config processes as described above. |                                                              | ![img](https://lh4.googleusercontent.com/8YqowTrPNm66lCFnXDby7lNOQUUmtKfvlNFwdDESq_kSCPcLIH3e3SJOlF1sDT9krh6euTfJTuwWnUuAcs4nfXg0t26kGZqp4SBjJe-Ex6AQs8RWIWUDnmXwrh55nWRZa2HgZHEH=s1600) |
| Context Switches                     | Voluntary context switches are writer processes that take a lock.  Involuntary context switches happen when a writer process has waited longer than a set threshold, and other waiting processes take over. | A high number of involuntary context switches indicates a CPU-bound workload. | ![img](https://lh4.googleusercontent.com/EdLrSvJs7CJAzR2Csnnpb2PUDm7GINSW7RUKj7PeLUFdtQ6Ythpp2RQcqgUInClk9SyPPyLgBkOfRn6j-YFJ-cnBSyCjufFTyUD-zU_mCC0xa6mxmHf7s4lBYMyobqMXW5Dx0bXn=s1600) |
| SpinLock Time/Server                 | Spinlock is a measurement of processes waiting for a server resource and using CPU to check and wait repeatedly until the resource is available. | This value can become very high on large machines with a high number of cores.  The gflag tserver_tcmalloc_max_total_thread_cache_bytes is by default 256MB, and this is generally sufficient for 16 core machines with less than 32GB of memory. For larger machines, increase this to 1GB or even 2GB. Monitor memory usage, because this will require more memory. | ![img](https://lh3.googleusercontent.com/wTVgOCi24Jyh4DB8TeOXzB7X0VmDqwnuOxmU1DSyif6wgJtgH0VKu9_HeNzmBf-v8gCNcGni6ldfi4gI1chl6_nHl8kpQXB5QSiHVe4JbjNiPS6qDPJTvWV2Qg3bmDc6Qapwo-iN=s1600) |
| TServer Log Latency / WAL Latency    | (Related to WALs) Commit (Log Group Commit Latency): Microseconds spent on committing an entire group. Append (Log Append Latency): Microseconds spent on appending to the log segment file. Sync (Log Sync Latency): Microseconds spent on synchronizing the log segment file. | These metrics can help understand how much time is spent writing to disk, and used to tune accordingly. | ![img](https://lh5.googleusercontent.com/-ncMPdTbCci_eF5eVkf2H740wtMpqPRk2_nAC2qS1-5Ss98jPmXTSuXEvPAl_K-LCYhYMfSHt4J0sE0RpDStkAN1MbnI2P3J36hnkTJ2VmCtRa4PLVRSy2YtDPZg_BfcLGe1bKLu=s1600) |
| Log / WAL Bytes Written / Sec / Node | Number of bytes written to the WAL since tablet start.       |                                                              | ![img](https://lh3.googleusercontent.com/ZLj1R9e-3078CdeEwtsRSpGfMmUNwx_hOitAd7ICTupvgXw-_EMCtiWmtIThht8VWkiWQV8w-S2a_ZsX516OttJiB5wUvYNIZ0HDCqIJ4wQj7GhfOKZASQc1h-KqJqkQo2il1S46=s1600) |
| Log / WAL Bytes Read / Sec / Node    | Number of bytes read from the WAL since tablet start.        | Alert on values higher than normal range. An increase indicates that followers are falling behind and are constantly trying to catch up. In an xcluster replication topology, this can indicate replication latency. | ![img](https://lh5.googleusercontent.com/7GPXKeQ2hehPbxP_rsf9RnWv2j0eOxFj2wLz6BPB4D_RPmmVt7yGjcvyS-EVsmA38W8ddpfZ0lp8tyE892ZDj5Dy4lrUHGhQbyCU-5InRW9hpUiFYfUUkz0YIsK4knkdnNBDVorv=s1600) |
| TServer Log / WAL Ops / Sec / Node   | (Related to WALs) Commit (Log Group Commit Count): Number of commits of an entire group, per second, per node. Append (Log Append Count): Number of appends to the log segment file, per second, per node. Sync (Log Sync Count): Number of syncs for the log segment file, per second, per node. |                                                              | ![img](https://lh3.googleusercontent.com/9vsTeJjTH5d_EzO8H-QyaS5x5tt5GG8MXHwcLIi4ExUgqwmMuSmPlEJuXz9t6pGMGB24l7X7MNFxS2CSIJijISJn8WQw7ufBiTe9Tza_tv4-R7Ny4LhTmYOk5xS9V42tHumNBTR-=s1600) |
| TServer TCMalloc Stats               | In Use (Heap Memory Usage): Number of bytes used by the application. This will not typically match the memory use reported by the OS, because it does not include TCMalloc overhead or memory fragmentation. Total (Reserved Heap Memory): Bytes of system memory reserved by TCMalloc. | See also: Free Heap Memory: Number of bytes in free, mapped pages in page heap. These bytes can be used to fulfill allocation requests. They always count towards virtual memory usage, and unless the underlying memory is swapped out by the OS, they also count towards physical memory usage. Unmapped Heap Memory: Number of bytes in free, unmapped pages in page heap. These are bytes that have been released back to the OS, possibly by one of the MallocExtension Release calls. They can be used to fulfill allocation requests, but typically incur a page fault. They always count towards virtual memory usage, and depending on the OS, typically do not count towards physical memory usage. Thread Cache Memory Limit: A limit to how much memory TCMalloc dedicates for small objects. Higher numbers trade off more memory use for -- in some situations -- improved efficiency. Thread Cache Memory Usage: A measure of some of the memory TCMalloc is using (for small objects). | ![img](https://lh5.googleusercontent.com/E0gpLq5PgvLeQll5udvyzPGQjI4rZdBd63eEMOPrnzJUorMU-a4p10Cfl_Ghk7f3CiYcaIElPjWuswFZ_JvJHxD4rKODSYcHujjNqehRqkSprGP1jxYG63NiPtcOM-ZAOZKlWGhI=s1600) |
| Log / WAL Stats / Node               | Log bytes read: Size (in bytes) of reads from the WAL since tablet start. Log cache size: The total per-tablet size of consensus entries kept in memory. The log cache attempts to keep all entries which have not yet been replicated to all followers in memory, but if the total size of those entries exceeds the configured limit within an individual tablet, the oldest will be evicted. | If log cache size is above zero, followers are behind. Consider alerting if the value spikes or remains above zero for an extended time. | ![img](https://lh5.googleusercontent.com/Jcv88L2OZjvAcZyMliTCNNIZfcoO-jj8HNzNRzCKugmCN3Gs-DrtD1hUbuy6TkI-qVg1tdcGH0H-7U_PNC_EGnXPqFPsi8-QHi1BJkbRKeGqyd7GJenua8hx59FQ8_eN7CJn3Ynu=s1600) |
| Log / WAL Cache Num Ops / Node       | Number of times the log cache is accessed.                   | Outside of an xcluster replication deployment, a number over zero means some followers are behind. | ![img](https://lh4.googleusercontent.com/7muWloIDHPebRXPbzTmfVKrThNsvV0ZXkttYZzpdbIdm56aa2zcAS32wZJJoFsE-W_9FXw48o1qtzkN_lptJE6uG5bCBDQ4XEUL2GOR-m63KObgjzjw1t8jbBuETroH9yBUCcWyh=s1600) |
| Glog messages                        | Logging is implemented in Yugabyte using the GLog library. This emits log at the severity levels of info, warning, and error. Info: Number of INFO-level log messages emitted by the application. Warning: Number of WARNING-level log messages emitted by the application. Error: Number of ERROR-level log messages emitted by the application. | Using a log aggregation tool is generally recommended for log analysis; routinely review log entries with the "error" severity. | ![img](https://lh6.googleusercontent.com/dhOb-FumeETyVl-LtJXVYPnmJAqtSBuFPh8ABXP6LOMYivbx33UpcOTKoZCNDvQu2VtzrEnUDlO7CCsrz5-cFEqeyy6LonTqGUINFkqDgBQZUAEYAxl3Rqpu0Q-Vp2DxnpbHMT2s=s1600) |
| RPC Queue Size                       | Number of RPCs in service queues for tablet servers. CDC (Change Data Capture) ServiceRemote Bootstrap ServiceTS RPC (Tablet Server Service)Consensus ServiceAdmin ServiceGeneric ServiceBackup Service | Queue size is an indicator of incoming traffic.  If the backends get overloaded, requests pile up in the queues. When the queue is full, the system responds with backpressure errors.  See also: rpcs_timed_out_in_queue - Number of RPCs whose timeout elapsed while waiting in the service queue, and thus were not processed. Does not include calls that were expired before we tried to execute them.rpcs_timed_out_early_in_queue - Number of RPCs whose timeout elapsed while waiting in the service queue, and thus were not processed. Timeout for those calls were detected before the calls tried to execute.rpcs_queue_overflow - Number of RPCs dropped because the service queue was full. | ![img](https://lh3.googleusercontent.com/QGI3t3MJzrNyO8-ntAalc_kee637aXjsqPvLeOWDGSyxQfsA5LL2xfqF13i7dHBbnPugEnHb6IK0A3IjRqworwuztlJ--VbF6hBOomnxRf2Xk2FAaQLy0gCeDkDdTIzbhjtj1Wh-=s1600) |
| CPU Util Secs / Sec (Tablet Server)  | Tablet server CPU utilization.                               | The tablet server should not use the full allocation of CPUs. For example, on a 4-core machine, 3 will be used by the tablet server, but if the utilization is regularly close to 3, you should increase the available CPUs. | ![img](https://lh4.googleusercontent.com/_-JIgKXftpR4Hhtbz_03Ij95LzAjb33YWO3Vdke2BD1A0U3iPmEjMuBOc6UUiC1kWuuldPYGpYvFezcohLP6wbyyjG6qrkkUZ9Sgzt2jI8hI3lfDUiA8QPxBZb6SLLWVOdtCCx7Y=s1600) |
| Inbound RPC Connections Alive        | Count of active connections to tservers.                     |                                                              | ![img](https://lh4.googleusercontent.com/4reXgXw5YRHGpkIJoLBH9n7DdRSxNiMFmNv7bWxhSM04MCB8LIiDsc4gspeud7nWA8CnvBvG2cU4SwYoBga4rxuv-ODvzWpi0uvpXmMWvaDjp59IEthjUJj230DURsA-kL3-F0i8=s1600) |

### Master Server

| **Graph**                           | **Description**                                              | **Alert Guidance**                                           | **Example**                                                  |
| ----------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Overall RPCs / sec                  | Number of created RPC inbound calls to the master servers.   | The limit is 1000 TPS on the master, but under normal circumstances this number should be much lower than the limit. Alert at a range under the limit, higher than your average. | ![img](https://lh4.googleusercontent.com/kjaOdoPCNBIkUzEzkvZFTIjqYbNqMM6mgm7yii9twZKpbutS4uVISW1BGJgkJWZXcHBFnYXQDDX_1LReWYJ8HOeiyGDnTWOxE0qDG6XYgcy6oolw1Ss388yFaa87j05JSKbGTNun=s1600) |
| GetTabletLocations / sec            | Number of times the locations of the replicas for a given tablet were fetched from the master servers. |                                                              | ![img](https://lh5.googleusercontent.com/MlK3tLpr9GIUs7BTaYh7U0XEiX2Ytlx4cJkO8OJsSU0QEXgYbe-t35d_ufHw23USV4ah9V3bOD_OPqVQiUCBZnLo3QL5tLxMUXIf6Vl86EXrB3-2RnBwGlcTB1V13cjZZXlyKgz8=s1600) |
| Master TSService Reads / sec        | Measure of YSQL reads of the postgres system tables.         |                                                              | ![img](https://lh6.googleusercontent.com/PtN9eJybKlouWE9GkRPMQUME7MhouiKUvqznO0mniW3Mz8qUNJAz2uXGeuuCQOnkC5S8NMx9M6rIXh1KrDwy6trLG8bNATtlyaY6qtWaGNJNTqFOzAlpd7s9gOvy-qjqaaR4xkou=s1600) |
| Master TSService Writes / sec       | Measure of YSQL writes to the postgres system tables (during DDL). |                                                              | ![img](https://lh4.googleusercontent.com/M4VujY_XmHpdfm9rxBqVTWMEIr4Wx6PEB3TPqTOyL7lgfUog8lTrdU9sK8wloKCQHIkLBxECctSKb68EwJ56ub-O7KVNoIIJSyK9jtKWjBb0G8tjxumxx8wfPGz46LRj6bEeHb_n=s1600) |
| TS Heartbeats / sec                 | Count of heartbeats received by the master server leader from the tablet servers, to establish liveness and report back any status changes. | This measure can be used to determine which master is the leader, because only the leader gets active heartbeats. | ![img](https://lh6.googleusercontent.com/uCb6uAqfiORHJVjyDzdPAHbfBhaytgctqQ8ZjOJgr-6YYezqaHmm1n6fT2V2o5Avc4KMwrq33tvYwEdFd8l_9LZNV2ZfHSUZ41zXMUENDcqhkJKLm5pqpDD7SxU8QFQ9y0UIQreB=s1600) |
| RPC Queue Size                      | Number of RPCs in service queue for master servers.          | Queue size is an indicator of incoming traffic.              | ![img](https://lh3.googleusercontent.com/ca2uMBdYsQGIYxbrMkRoYZBmw0NAjkmxgZj9Sqam8UtdNrFslcit8q3I5NWOElDzgAUQxDhi_czxtbQXBoXEjQDI4buouV8Jby7388kzl1_3ALaqiek9szOshtduG5KU-ROB8bDk=s1600) |
| UpdateConsensus / sec               |                                                              |                                                              | ![img](https://lh3.googleusercontent.com/StGC2HRiaEk0gSNXa3iRdPxe6sKnW9U_xgdz1FX-aMbqI3Tb2ShjMpw59U-GaCquO_lN9nsZnsVBtrjDxVSGiprKan-pktJ3OE5WoSlnWEZ8Qukh4JJ4jFPqVUoBl5jzmXkoLDg9=s1600) |
| Create/Delete Table RPCs            | Count of administrative operations CreateTable and DeleteTable. | A deletion can fail when other operations, like bootstrap, are running. Uses a configured retry timeout. | ![img](https://lh3.googleusercontent.com/hUvx5wlfPfvaxLePge0B49F1TX_0oXRpSHINFOWYf8bOnO_NRJSl7Y_RbKRuxIjuOdpIdPZ8uhqrrMg1GzNobud2jPCbxxI4nFLrQH6tB36ORPP6dIuaM8Pk5BEpEQ24zWMt_4Nz=s1600) |
| CPU Util Secs / Sec (Master Server) | Master server CPU utilization.                               | The master server should not use a full CPU.                 | ![img](https://lh4.googleusercontent.com/VOehK1IY4DB-ZWVUfVP9FWbbrVHYO97zyA5yD5qKUP2vEVhM2xGiJxjzpeog9rjWf9QfTTB-q1Wg4uq-qCTYln4v0e7Ci5gFeHLV1drsQOlVShDedVASvH2JZv2dIqXOEfGVrCm0=s1600) |
| Inbound RPC Connections Alive       | Count of active connections to master servers.               |                                                              | ![img](https://lh5.googleusercontent.com/tpEFlDFXFH0l19Os89oxQRX2MEj5_LkDxpQV44cTBtLcFBnaX2pvBgKwD_A8qFBq80HG1u_1YmaUooyYkiIIOPWUAQSuZDITqyBQy1Bbl9wNc3HlHp8O6X1TLHPsoOgyiz9rFuxm=s1600) |

### DocDB

DocDB uses a highly customized version of[ RocksDB](http://rocksdb.org/), a log-structured merge tree (LSM) based key-value store. Most of these metrics will be used internally by engineering if troubleshooting a deployment, and are not great candidates for alerting.

| **Graph**                   | **Description**                                              | **Alert Guidance**                                           | **Example**                                                  |
| --------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| LSM-DB Seek/Next Num Ops    | The number of calls to seek/next.                            |                                                              | ![img](https://lh5.googleusercontent.com/uvpTRiN-Fa4JPjnroO17RJ_eA93cwje8WhXr9zBVmScNj5q0noAv1cx3AaN1pZ84xogNO9y-fS0ttLAiTBurNWVErQgo_V7k3oqkzcUll8Hv2K2Rs0I3oTE77p55g_0aq2e_3Ib9=s1600) |
| LSM-DB Seeks / Sec / Node   | The number of calls to seek per second per node.             |                                                              | ![img](https://lh6.googleusercontent.com/uoUOhLPiMl8HWhSeWC0NarQWqnuooGyn2f2KL03KB-vi28mABzIuQS0cUWev5dPQZKTgo8VTEIn4oTI-4IfFKesM_Otmc9E-ZZ0qz0B2QOSFust7xD6oIbX_6i5qAdCmAlugdn3K=s1600) |
| SSTable size / Node         | Size (in bytes) of all SST files.                            |                                                              | ![img](https://lh4.googleusercontent.com/GBgsIyFFT4OdyNfrGv6rPMGagKNgObclSf5NxCbT9BU_WxgThWVh4Eu_Vl7yEMHJ_Dde_axM4oYgGZR7l7NQbU3RYoQFW0CnUWY-kNeZXIQl9RZ383bCW6PsXqdHuSIgsQ5a7iZ8=s1600) |
| Average SSTables / Node     | Average number of SST files across nodes.                    |                                                              | ![img](https://lh6.googleusercontent.com/_zuXgSrAvHTbVKLIKz3aDr1ulmIV9kPoO9AVv76IQYxeqygtrhjYAzaAnyhuZ90s-XZszRQlfgDGYeKk2WynZt9d4PDeg7uvk-SM6Jg02002xK_ojgIhwK1L_njmm31NuiromoeY=s1600) |
| LSM-DB Get Latencies        | Latency in time (in microseconds) to retrieve data matching a value. |                                                              | ![img](https://lh4.googleusercontent.com/PR6HJ7-5LGNFZcfOreM_Q6WnZco13ZKvG9tn_xRDRS0-5WHStkvQclHsSKa2ZIUqrQMJFjLdJiM48S8CGpcHQOch07XuhJu77Y6fOUENMjzxH6Pc9eFqTXgCZNFlYdV20bGBcTiZ=s1600) |
| LSM-DB Write Latencies      | Latency in time (in microseconds) to write data.             |                                                              | ![img](https://lh5.googleusercontent.com/PV-M1e4KMuBqIcmfaU0x-ZfLX7VCw4Tm6e0QsUMcsDrFCRwdTiaN97B-vD5jIDlMZ5LxK2NWspGEHPgB6V1Uu8xIKDfdWTCgqXwYm5cKYcy4Nqe35edtLnkUaBtyO9Yq0J3XkNGA=s1600) |
| LSM-DB Seek Latencies       | Latency in time (in microseconds) to retrieve data in a range query. |                                                              | ![img](https://lh5.googleusercontent.com/jfrlTDPl3W0y7BnNNEvzovgsq6yGNkRVmMzKXylBlOnO5IcDiphpAdblMLdsb6oPzIN3xfqvV34XKmemUYtsAVlEXudCOCGkrZ-Da3Gv6ZFjdOMe4e3jPmZwDM0YYjTl4JU27xpp=s1600) |
| LSM-DB Mutex Wait Latencies | The wait time (in microseconds) for the db mutex. This mutex is held for meta operations, such as checking data structures before and after compactions or flushes. |                                                              | ![img](https://lh3.googleusercontent.com/UTLm9bfbmpgjTgxZwzMVG8NL5SEHDZ15gFzLN1cf18KbaMwRFkgQ6JBmJrw9Iot4p9CtL8Ocp73tUyVwJDXdPRZDlGn6EoYx7fFrD09C06jBoktBJ4POsh6pLilPZdPw4PuOs0k3=s1600) |
| Cache Hit & Miss            | Hit: Total number of block cache hits (cache index + cache filter + cache data). Miss: Total number of block cache misses (cache index + cache filter + cache data). | If misses is high...                                         | ![img](https://lh3.googleusercontent.com/cMiPPjsJ8VBaMGk8nzEKr5IcLEIH3XwDx76REDBxl-a8eeuhKJBEIrCCIg-zvRyI5qI-d911WF6agdkYUuiGsotWP7BXkTsJIl1x0CzDT1LE49LeerZKPPVo42c1P6Rg7GoGxRpQ=s1600) |
| Block cache usage           | The RocksDB block cache was enhanced by Yugabyte to become scan-resistant, using a MySQL/HBase-like midpoint insertion strategy. A block requires multiple touches before being added to the multi-touch (hot) portion of the cache. Multi Touch: The size (in bytes) of cache usage by blocks having multiple touches as described above. Single Touch: The size (in bytes) of cache usage by blocks having only a single touch. |                                                              | ![img](https://lh3.googleusercontent.com/MR2y-VXEu113SGC5TV9ZA8WBKquBD0Y5iSTGJHiFTJkOjP5IedIFxo7Try2eIxdd2OHc1U80flVv9tvHdeLP188i6ycwpwn1_hu2GyLDLhfXClM_Yv8WCj_7yXFY6zB9uNc69wrN=s1600) |
| LSM-DB Blooms usefulness    | Blooms checked: The number of times the bloom filter has been checked. Blooms useful: The number of times the bloom filter has avoided file reads (avoiding iops). | Bloom filters are hash tables used to determine if a given sstable has the data for a query looking for a particular value. Bloom filters are not helpful for range queries. | ![img](https://lh5.googleusercontent.com/uo2aYRfKxDO1tgpQBaI5rFhaWnYmOs_TCmTCXZeu0daV-vI4apaDWkyq3lvqKfYYwcRbXKY4kzAKG_p4cAebDm4k7KDOOwq8BsxG4CTPqUTs1ses5hZFtNQM_UOLViHWPG6NUPJK=s1600) |
| Stalls                      | Time (in microseconds or milliseconds) the writer has to wait for compactions or flushes to finish. |                                                              | ![img](https://lh5.googleusercontent.com/59_ZCcAKdChFCyy7jRcrX6fwp6xQx8lWsru6827Wibqg4HjeeJ18hx6DAgMVfqGQNh9cVEfxH6q151TnZHr88cYWn62NHKZtUGn-95AHW2RTFyxsqSav7VjBLJlAHtK9jNgYpcGt=s1600) |
| Rejections                  | Number of RPC requests rejected due to the number of majority SST files. | Rejections can happen due to hitting the soft limit on SST files, hitting more than the soft memory limit (set to 85% of the hard limit), etc. | ![img](https://lh5.googleusercontent.com/ePNnx2FWQvP7NJWa9EWhvXFv-v_1-7TzeOyh_0Toq_F0suajGdNTqQZE0YkPjD2GsaN5Y3jFTZWfpnv6b1qBOABlQWemtvkouRDoBTI_ZuluiccVnYNXCmEPS9xEpG-2N_TuhfCY=s1600) |
| Flush write                 | Bytes written during the flush process.                      |                                                              | ![img](https://lh3.googleusercontent.com/ZZMi832bifDZSfeLvpggvd1GLW_xc--rVEc8eOIQ5jxzWfTP8hE58etmD2St7zuWHAygJGn7xTp9-C5RqqkzcWduGe3GaOqBzaIovexeI23-8yEJxa8FpTYOVb73i2Y6MAb2vDHl=s1600) |
| Compaction                  | Indicates how many bytes are being read and written to do compaction. If not much data is being deleted, these levels will be similar. Sometimes you will see a large delete, indicated by large reads but low writes afterwards (because a large percentage of data was removed in compaction). |                                                              | ![img](https://lh4.googleusercontent.com/hUoEeoABnRYbgOWiLa3gxNjZhsiyQcD1nG_GFZWKFnC2ttb0q3-wm-WCHJ-_vArRcVnU56tuagDDQ3iV-bP6SMPu13MP6rgiY3uKALje5B2xZ5YIR65DSiC5URIazLOWTaqE4gAI=s1600) |
| Compaction time             | Time (in milliseconds) for the compaction processes to complete. |                                                              | ![img](https://lh3.googleusercontent.com/BHnw4h3hOVTHIljt-X4aRomJYnBfpljQkiUahDbZDKAYj_yFzDVB2_hqkkILuKRS4C5J0t_GnAWpDbtFwJKa5yO8mfh--6auGaEB3dBelUj8r4qHCGw2Eb_XkIAi9ENFMSe6l22B=s1600) |
| Compaction num files        | Average number of files in any single compaction.            |                                                              | ![img](https://lh6.googleusercontent.com/hZ9MIrk2CMfGgqlnK8Err236oheZEFW9W1pQs4pINEedesMyT1I7f4McID4sXapjNE8eQooPSQ-fkkUqIcH_TUBrVbN3ODVOqIQAOkg58oD_M5OQOQ2wCI4FbhcYM2StoQVJ4Sdo=s1600) |
| Transaction                 | Expired Transactions: Number of expired distributed transactions. Transaction Conflicts: Number of conflicts detected among uncommitted distributed transactions.  Related to the process that resolves conflicts for write transactions. This process reads all intents that could conflict and tries to abort transactions with a lower priority. If a write transaction conflicts with a transaction having a higher priority, then an error is returned, and this metric is iterated. |                                                              | ![img](https://lh6.googleusercontent.com/8G3tUNH8rvRfEH-eI7-iED-tRfJcyjKsmjzbZOnHA8YBA184gaYQEOdgzsjZAMb9E-bN5qvBzF3alaWaakJeHEoTVKpE1nlPi8x1rFhxRZeQ59dza9ZqrrpL6oZVGxL9VDZaaft7=s1600) |

### Replication

| **Graph**             | **Description**                                              | **Alert Guidance** | **Example** |
| --------------------- | ------------------------------------------------------------ | ------------------ | ----------- |
| Async Replication Lag | Maximum lag across all tables in an xcluster replication deployment. |                    |             |

















## Use Nodes Status

In the [Admin Console](../../install-yugabyte-platform/), click on the [Universe](../../../architecture/concepts/universe/) page, then go to the **Nodes** tab.
The page will show the status of the Master and TServer on each YugabyteDB node.

![Yugabyte Nodes Page](/images/troubleshooting/check-node-status.png)

In case of issues, more information about each Master or TServer is available on its respective Details page.
Generally the link is: `<node-ip>:7000` for Masters and `<node-ip>:9000` for TServers.

Note that in some setups, these links may not be accessible, depending on the configuration of your on-premises  data center or cloud-provider account. To fix this, read more [here](../../../troubleshoot/nodes/check-processes/).

## Check Host Resources on the Nodes

To check host resources on your YugabyteDB nodes, run the following script, replacing the IP addresses with the IP addresses of your YugabyteDB nodes.

```sh
for IP in 10.1.13.150 10.1.13.151 10.1.13.152; \
do echo $IP; \
  ssh $IP \
    'echo -n "CPUs: ";cat /proc/cpuinfo | grep processor | wc -l; \
      echo -n "Mem: ";free -h | grep Mem | tr -s " " | cut -d" " -f 2; \
      echo -n "Disk: "; df -h / | grep -v Filesystem'; \
done
```

The output display will look similar to this:

```
10.1.12.103
CPUs: 72
Mem: 251G
Disk: /dev/sda2       160G   13G  148G   8% /
10.1.12.104
CPUs: 88
Mem: 251G
Disk: /dev/sda2       208G   22G  187G  11% /
10.1.12.105
CPUs: 88
Mem: 251G
Disk: /dev/sda2       208G  5.1G  203G   3% /
```

